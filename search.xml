<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>B站OpenBMB视频</title>
      <link href="/2024/03/11/page/"/>
      <url>/2024/03/11/page/</url>
      
        <content type="html"><![CDATA[<h1 id="啥事没干今天"><a href="#啥事没干今天" class="headerlink" title="啥事没干今天"></a>啥事没干今天</h1><p>还是看了大模型偏见与公平性的综述，继续评估标准，又看了预处理的一些东西</p><p><del>综述看的太无聊太累了</del></p><p>然后就是看了OpenBMB那个大模型知识普及的视频，从注意力到huggingface的小demo<br>大致流程也跟我之前写的huggingface一致</p><p>然后是突发奇想，想要fine-tune一个大模型专门给我写小说看。</p><p>这篇综述还是要看完的，但是我决定交给txyz来读了，到时候复制一下就行。</p><p>kaggle上用了下gemma，没搞懂，有个prompt格式，我不太理解是为什么<br>我认为下一步有需要了解训练数据或者微调数据进入大模型之后是如何训练的</p><h1 id="大模型语言排行榜"><a href="#大模型语言排行榜" class="headerlink" title="大模型语言排行榜"></a>大模型语言排行榜</h1><p>找到一个huggingface上对开源大模型的排行榜<br><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">排行榜</a></p><h1 id="关于vercel的一点点"><a href="#关于vercel的一点点" class="headerlink" title="关于vercel的一点点"></a>关于vercel的一点点</h1><p>刚刚搞了一下图床的东西<br>跟随的教程是<a href="https://www.fomal.cc/posts/d7fb1ba1.html#post-comment">博客</a><br>我的这个博客也是跟着他做的，可以说是相当厉害了</p><p>这个图床是怎么做的呢<br>首先要在github创建一个仓库，然后本地git你想要的图片上去<br>再用<a href="https://vercel.com/">vercel</a>导入刚刚的仓库<br>在项目domain中新增解析地址，使用已经有的域名进行替换<br>比如我买了一个域名xxxxxx.com什么的，我就在前面新加一个二级域名比如picpool.xxxxxxxx.com，然后我就在阿里云的DNS解析中为我的主域名添加解析，依据vercel给的配置依次填入解析项中，然后就能用这个url访问我的github的资源。</p><p>这个很有趣，相当于把GitHub仓库当作服务器存储空间，而vercel作为服务提供者为你返回资源，我想后期可以写一些api什么的，在我vscode的ai聊天或者别的插件里用用？</p><p>把QQ聊天或者甚至是阴阳师当作插件写到vscode里？<br>开发一个正大光明的摸鱼插件</p><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><ul><li><input disabled="" type="checkbox"> 完成大模型公平性综述</li><li><input checked="" disabled="" type="checkbox"> 图床</li><li><input disabled="" type="checkbox"> 尝试训练一个大模型进行小说生成</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 学习日常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智能计算系统实验一</title>
      <link href="/2024/03/09/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E5%AE%9E%E9%AA%8C%E4%B8%80/"/>
      <url>/2024/03/09/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E5%AE%9E%E9%AA%8C%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络设计实验"><a href="#神经网络设计实验" class="headerlink" title="神经网络设计实验"></a>神经网络设计实验</h1><p>开始写课程作业了，努努力看看能不能一天写完，现在是早上10点45，一会吃饭去下午回来开始写，早上又在开小差什么的，下午一定认真写。</p><p>课程实验是用本地连接服务器的方式完成的，用的vscode ssh链接，用一下发现挺简单的，等我这个实验做完了我就去搞一个4090的电脑跑一下大模型玩玩看。😏</p><blockquote><p>要注意的是，链接进ssh后，需要在文件位置选择&#x2F;opt&#x2F;目录下的实验</p></blockquote><p>而且，我计划是从实验平台上将文件下载下来在本地编写后再在实验平台上评测，这样100H的机时应该可以用很久。</p><p>由于提交分数是<strong>取最后一次而不是最高分</strong>，所以记得要用git记录下版本，在最后提交最高分的那个版本即可。</p><p>下午记得看看那个代码存储在哪，不太明白这个额外创建的卷是怎么用的</p><h2 id="全连接手写数字识别"><a href="#全连接手写数字识别" class="headerlink" title="全连接手写数字识别"></a>全连接手写数字识别</h2><p>新学会一个技能，vscode要打开一个新窗口而不占用本窗口可以</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ctrl+Shift+N</span><br></pre></td></tr></table></figure><p>这个实验相当简单 <del>也不一定</del><br>我们的任务是构建一个全连接网络，一共有三种层需要我们手动实现，全连接层、ReLU层、Softmax层。每层都要实现forward和backward，</p><p>我们先看全连接层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FullyConnectedLayer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_input, num_output</span>):  <span class="comment"># 全连接层初始化</span></span><br><span class="line">        self.num_input=num_input</span><br><span class="line">        self.num_output=num_output</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\tFully connected layer with input %d, output %d.&#x27;</span> % (self.num_input, self.num_output))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_param</span>(<span class="params">self, std=<span class="number">0.01</span></span>):  <span class="comment"># 参数初始化</span></span><br><span class="line">        self.weight = np.random.normal(loc=<span class="number">0.0</span>, scale=std, size=(self.num_input, self.num_output))</span><br><span class="line">        self.bias=np.zeros([<span class="number">1</span>, self.num_output])</span><br><span class="line">        show_matrix(self.weight, <span class="string">&#x27;fc weight &#x27;</span>)</span><br><span class="line">        show_matrix(self.bias, <span class="string">&#x27;fc bias &#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>): <span class="comment"># 前向传播计算</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        self.<span class="built_in">input</span> = <span class="built_in">input</span></span><br><span class="line">        <span class="comment"># TODO：全连接层的前向传播，计算输出结果</span></span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        self.output = np.dot(self.<span class="built_in">input</span>, self.weight) + self.bias</span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        <span class="keyword">return</span> self.output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, top_diff</span>):   <span class="comment"># 反向传播的计算</span></span><br><span class="line">        <span class="comment"># TODO：全连接层的反向传播，计算参数梯度和本层损失</span></span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        self.d_weight = np.dot(self.<span class="built_in">input</span>.T, top_diff)</span><br><span class="line">        self.d_bias = np.<span class="built_in">sum</span>(top_diff, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        bottom_diff = np.dot(top_diff, self.weight.T)</span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        <span class="keyword">return</span> bottom_diff</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_gradient</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.d_weight,self.d_bias</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_param</span>(<span class="params">self, lr</span>):  <span class="comment"># 参数更新</span></span><br><span class="line">        <span class="comment"># TODO：对全连接层参数利用参数进行更新</span></span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        self.weight = self.weight - lr * self.d_weight</span><br><span class="line">        self.bias = self.bias - lr * self.d_bias</span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_param</span>(<span class="params">self, weight, bias</span>): <span class="comment"># 参数加载</span></span><br><span class="line">        <span class="keyword">assert</span> self.weight.shape == weight.shape</span><br><span class="line">        <span class="keyword">assert</span> self.bias.shape == bias.shape</span><br><span class="line">        self.weight=weight</span><br><span class="line">        self.bias=bias</span><br><span class="line">        show_matrix(self.weight, <span class="string">&#x27;fc weight &#x27;</span>)</span><br><span class="line">        show_matrix(self.bias, <span class="string">&#x27;fc bias &#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_param</span>(<span class="params">self</span>):    <span class="comment"># 参数保存</span></span><br><span class="line">        show_matrix(self.weight, <span class="string">&#x27;fc weight &#x27;</span>)</span><br><span class="line">        show_matrix(self.bias, <span class="string">&#x27;fc bias &#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.weight, self.bias</span><br></pre></td></tr></table></figure><p>forward和参数更新都相当简单，主要搞清楚矩阵是如何相乘的，<br>首先就是输入x，维度为1 * input_dim，然后就是权重矩阵input_num * output_num<br>偏置就是1 * output_num<br>重点就是backward如何计算</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.d_weight = np.dot(self.input.T, top_diff)</span><br></pre></td></tr></table></figure><p>为什么权重是这样子的。<br>从全连接公式说起<br>每一层的公式是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Y` = W.T * X + b</span><br><span class="line">维度分别是</span><br><span class="line">Y`_(1*out_num)</span><br><span class="line">W_(input_num*output_num)</span><br><span class="line">X_(1*input_num)</span><br><span class="line">b_(1*1)</span><br><span class="line"></span><br><span class="line">损失公式去均方误差</span><br><span class="line">L = 0.5(Y - Y`)^2</span><br><span class="line"></span><br><span class="line">损失是权重和偏置的函数，要求对权重和偏置的偏导</span><br><span class="line">就要用到链式法则，先求对Y`的导数再求Y`对权重或偏置的导数</span><br><span class="line"></span><br><span class="line">此时dL/dY` = -(Y - Y`), 这个也就是top_diff记作ΔLy,形状是(1*output_num)</span><br><span class="line">dY`/dW = X,形状是(1*input_num)</span><br><span class="line">此时dL/dW = ΔLy * X</span><br><span class="line">显然这么写肯定不能乘的</span><br><span class="line">考虑到要对权重进行更新，因此dL/dW = X.T * ΔLy，这也就是为什么代码要这么写的。</span><br></pre></td></tr></table></figure><blockquote><p>为什么会标注矩阵形状就是因为我不知道有的公式为什么矩阵可以这么相乘</p></blockquote><p>其它层也都是同理的分析方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReLULayer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\t Relu layer&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  <span class="comment"># 前向传播的计算</span></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        self.<span class="built_in">input</span>=<span class="built_in">input</span></span><br><span class="line">        <span class="comment"># TODO：ReLU层的前向传播，计算输出结果</span></span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        output = np.maximum(<span class="number">0</span>, self.<span class="built_in">input</span>)</span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self, top_diff</span>):   <span class="comment"># 反向传播的计算</span></span><br><span class="line">        <span class="comment"># TODO：ReLU层的反向传播，计算本层损失</span></span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        bottom_diff = top_diff * (self.<span class="built_in">input</span> &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># ==============================================================================================</span></span><br><span class="line">        <span class="keyword">return</span> bottom_diff</span><br></pre></td></tr></table></figure><p>backward为什么这么实现，是因为relu层本身不含有参数，它作为滤网将非零结果前向和反向传播，因此只需要让梯度乘上一个mask让非0梯度传回即可。</p><blockquote><p>这里，self.input &gt; 0会产生一个布尔数组，其中大于0的输入位置是True（对应于1），其余是False（对应于0）。将这个数组与top_diff相乘，就可以实现只有当输入大于0时，误差梯度才会传回</p></blockquote><p>剩下softmax层我不想说了有点累睡午觉了，不过挺简单的。<del>我其实不知道为什么backward为什么这么写</del> 下次再说</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class SoftmaxLossLayer(object):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        print(&#x27;\tSoftmax loss layer.&#x27;)</span><br><span class="line">    def forward(self, input):  # 前向传播的计算</span><br><span class="line">        # TODO：softmax 损失层的前向传播，计算输出结果</span><br><span class="line">        input_max = np.max(input, axis=1, keepdims=True)</span><br><span class="line">        input_exp = np.exp(input-input_max)</span><br><span class="line">        exp_sum = np.sum(input_exp, axis=1, keepdims=True)</span><br><span class="line">        # ==============================================================================================</span><br><span class="line">        self.prob = input_exp / exp_sum</span><br><span class="line">        # ==============================================================================================</span><br><span class="line">        return self.prob</span><br><span class="line"></span><br><span class="line">    def get_loss(self,label):  # 计算损失</span><br><span class="line">        self.batch_size=self.prob.shape[0]</span><br><span class="line">        self.label_onehot=np.zeros_like(self.prob)</span><br><span class="line">        self.label_onehot[np.arange(self.batch_size),label]=1.0</span><br><span class="line">        loss=-np.sum(np.log(self.prob)*self.label_onehot)/self.batch_size</span><br><span class="line">        return loss</span><br><span class="line">    def backward(self):   # 反向传播的计算</span><br><span class="line">        # TODO：softmax 损失层的反向传播，计算本层损失</span><br><span class="line">        # ==============================================================================================</span><br><span class="line">        bottom_diff = (self.prob - self.label_onehot) / self.batch_size</span><br><span class="line">        # ==============================================================================================</span><br><span class="line">        return bottom_diff</span><br></pre></td></tr></table></figure><p>然后就是读测试数据啊构建模型什么的这也都相当简单。</p><h2 id="DLP实验平台"><a href="#DLP实验平台" class="headerlink" title="DLP实验平台"></a>DLP实验平台</h2><blockquote><p>我快笑死了，这个实验只要把模型搭建起来就行了，要满分的条件是DLP运行时间是CPU运行时间的五十分之一，哈哈哈哈我直接让CPU代码里的layer层每层都加了个sleep，直接给我干满分了</p></blockquote><p>这个没什么好讲的复制粘贴改下参数就行。<br>也不是很想学这个加速以后要用再说<br>要使用这个pycnnl库首先就是要</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install swig</span><br></pre></td></tr></table></figure><p>然后在目录下运行pycnnl文件夹里面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./build_pycnnl.sh</span><br></pre></td></tr></table></figure><p>好像是这个我名字忘记了好了不写了我要休息了</p><p>突然找到了一个学长的实验答案，虽然可能代码有变动但是有一定的参考价值<br><a href="https://github.com/doongz/aics/tree/main">智能计算系统</a></p><h1 id="MD"><a href="#MD" class="headerlink" title="MD"></a>MD</h1><p>无语死了，昨天好好的ssh用着突然用不了，点击连接主机没有反应，就是错误没有提示也没有。</p><p>试了重新加载vscode，重新启动，没有用<br>我就去问了GPT，它给了好多解决方案，我就一个一个去试了试，因为没有任何错误提示我也很无从下手的。</p><p>经过几个方案之后错误依然没有任何好转，完全就是正常使用的时候突然无法使用还不告诉你为什么不能使用，我挺无奈。</p><p>gpt就告诉我可以打开vscode开发者模式可以看运行过程中有没有错误在控制栏中给出但是并没用用提示框提示用户，然后我就打开了，里面确实出现了一个错误和一个警告</p><blockquote><p>【warning】An iframe which has both allow-scripts and allow-same-origin for its sandbox attribute can escape its sandboxing.</p><p>【error】Cannot read properties of undefined (reading ‘after’): Error: Cannot read properties of undefined (reading ‘after’)<br>at l.h (d:\Microsoft VS Code\resources\app\out\vs\workbench\api\node\extensionHostProcess.js:150:185186)</p></blockquote><p>因为错误并没有出现在extensions文件夹里，我就以为可能不是插件的问题，可能是vscode本体因为我可能操作顺序问题导致了不给弹窗，</p><p>然后我就到处搜这两个问题，完全没有搜到跟我这个相关。反正时间花费了很久。</p><p>我就又去问gpt了，它就告诉我可以清空本地扩展缓存什么的，清除重新加载vscode再下载插件排除问题，因为就ssh一个插件是我要实验的，就这么清除缓存和下载vscode搞了几次还是不行，我就又去搜索相关问题了，翻翻看可能会不会有别的相似的问题能解决这个问题。</p><p>反正就是搞了好久，差点就要去定位源码一个一个去分析了，我把插件版本回退之后就又好了，无语死了也不知道这次会不会用着用着就用出问题。</p><p>等我把实验都拿满分了就把我的实验过程给补完，这种从0开始搭建网络的还是比较有趣的。</p><p><strong>最好是把插件更新一个保存一个文件就自动提交部署这个功能给更新了</strong></p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 更新插件让它能在保存时自动提交</li><li><input disabled="" type="checkbox"> 搞个图床，找一些高清图像资源，把博客背景和文章封面什么的都换了</li><li><input disabled="" type="checkbox"> 完成第一篇大模型公平性文献阅读</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 学习日常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello_huggingface</title>
      <link href="/2024/03/07/hello-huggingface/"/>
      <url>/2024/03/07/hello-huggingface/</url>
      
        <content type="html"><![CDATA[<h1 id="huggingface"><a href="#huggingface" class="headerlink" title="huggingface"></a>huggingface</h1><p>今天也是用了下huggingface，不过也遇到了很多问题。<br>一开始直接将模型页面的试用代码放上来运行了，虽然下载了很多包，但是运行碰到了没有权限access这个model<br>然后就是搜了很多很多的方法，试了几个比如代码中添加token什么的都没解决问题。</p><p>然后去看了文档，<br>首先就是要运行下面的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install huggingface_hub</span><br><span class="line">huggingface-cli login</span><br></pre></td></tr></table></figure><blockquote><p>这个会让你填入api_token，这个在个人信息那里创建一个复制过来就行，<br>不过复制到里面会显示不见，而且最好不要用Ctrl-V的方法，它提示右键复制会好一点</p></blockquote><p>然后就是下载模型，等等就行<br>7b的我16G内存运行不了，只能运行2b的，后续考虑用别的方法调用模型会好一点？🙄</p><p>在7b量化的运行中也出现了问题现在还没解决，好烦🙄</p><p>怪事，在huggingface上面运行的模型回复长度好长，本地运行的就回复几个词的<br>然后就是下载的huggingface的模型会在本地存储，存储位置在</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\78752\.cache\huggingface\hub</span><br></pre></td></tr></table></figure><p>记得删掉</p><h1 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h1><ul><li><input checked="" disabled="" type="checkbox"> 看一下本地部署大模型的技术栈</li><li><input disabled="" type="checkbox"> 完成第一篇大模型公平性文献阅读</li><li><input disabled="" type="checkbox"> 插件更新一个保存文档就会自动部署提交</li><li><input disabled="" type="checkbox"> 图床图床图床</li><li><input disabled="" type="checkbox"> GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech Detection?</li><li><input disabled="" type="checkbox"> Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 学习日常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bias and Fairness in Large Language Models A Survey</title>
      <link href="/2024/03/05/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%81%8F%E8%A7%81%E4%B8%8E%E5%85%AC%E5%B9%B3%E6%80%A7/"/>
      <url>/2024/03/05/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%81%8F%E8%A7%81%E4%B8%8E%E5%85%AC%E5%B9%B3%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="公平性与偏见（1）"><a href="#公平性与偏见（1）" class="headerlink" title="公平性与偏见（1）"></a>公平性与偏见（1）</h1><p>首先就是大模型的背景，大模型在大语料库的训练下具有很强的零或少样本的学习能力，能在很多下游任务上取得很好的效果，但正因如此，大语料库隐含的偏见有可能被大模型捕捉而学习，从而影响下游任务产生偏见。</p><p>这篇文章主要从三个方面介绍</p><ul><li>评估矩阵</li><li>评估数据集</li><li>去偏算法</li></ul><p>文章的贡献有</p><ul><li>NLP 的社会偏见和公平定义的巩固、形式化和扩展</li><li>偏差评估指标的调查和分类</li><li>用于偏差评估的数据集的调查和分类，以及公开数据集的汇编<blockquote><p><a href="https://github.com/i-gallegos/Fair-LLM-Benchmark">公开数据集</a></p></blockquote></li><li>减轻偏见技术的调查和分类</li></ul><h2 id="公式化大模型偏见与公平性"><a href="#公式化大模型偏见与公平性" class="headerlink" title="公式化大模型偏见与公平性"></a>公式化大模型偏见与公平性</h2><ol><li>对大模型的定义</li></ol><p>文章将大模型定义为：由 θ 参数化的大型语言模型 (LLM) M 是一种基于 Transformer 的模型，具有自回归、自动编码或编码器-解码器架构，已在包含数亿到数万亿个标记的大型语料库上进行了训练。</p><ol start="2"><li><p>对大模型偏见的定义</p><ul><li>社会偏见与公平性<blockquote><p>这里有讲到当一个标签被贴到一个群体上使得群体的边界合法化，此时就强调了这个群体与其它群体之间的差异，而这个差异则会导致强化社会等级制度和权力失衡，通常会带来非常真实和物质的后果，可能导致隔离、边缘化和压迫。</p></blockquote></li></ul><p> 社会群体的定义</p><blockquote><p>具有相同身份特征的人口子集，该特征可能是固定的、特定背景的或社会构建的。</p></blockquote><p> 受保护属性的定义</p><blockquote><p>确定社会群体身份的共享特征</p></blockquote><p> 群体公平性</p><blockquote><p>要求任意两个群体之间以群体身份进行测量的结果应当是相似的</p></blockquote><p> 但显然一个人并不一定只属于一个群体，当一个人可能属于多个群体的时候，单个群体的公平性可能很难保证个人的公平性<br> 因此个人公平性的定义</p><blockquote><p>原文中的定义是在某些任务中相似的人应当获得相似的待遇</p></blockquote><p> 但是我看公式的意思应该是模型对任意两个人的输出差异应当小于这两个人原本的差异</p><p> 社会偏见来源于由于历史和结构性权力不对称而产生的社会群体之间不同待遇和结果，这可能就导致NLP模型的各种直接歧视和间接歧视</p><ul><li>NLP任务中的偏见</li></ul><p> 论文在这里论述了一堆，说了很多关于语言在偏见方面的能力。然后就介绍到在NLP中会出现的偏见</p><p> 文本生成体现的局部偏见和总体偏见</p><blockquote><p>局部偏见就是一个句子中对相近词语的替换，比如男性换成女性，然后来评估模型结果的差异。<br>总体偏见就是全部句子体现的模型对于某一个群体的情绪</p></blockquote><p> 机器翻译中可能会默认使用男性词汇作为标准，比如我很快乐让模型进行转述时候模型会用他很快乐而不是她</p><p> 信息检索中即使使用非性别指导的查询，模型依然会返回更多的男性相关的文档。</p><p> 问答系统的偏见可能在于在大规模的语料库预训练之后捕捉到了人们对某一群体的偏见，而在回答问题中体现这些偏见。</p><p> 分类任务中，模型可能会将部分群体的内容分类为负面结果</p><p> 自然语言推理中的偏见问题</p><blockquote><p>在自然语言处理中，自然语言推理（NLI）是一项重要的任务，旨在判断两个句子之间的逻辑关系。这些逻辑关系通常分为三种：蕴含（entailment）、矛盾（contradiction）和中立（neutral）。蕴含意味着第一个句子（前提）逻辑上支持第二个句子（假设）的真实性；矛盾意味着前提与假设在逻辑上不可能同时为真；中立则是指前提与假设之间没有直接的逻辑关系。</p><p>这段话提出的问题是，在进行自然语言推理时，一些模型可能会依赖于错误的表述或者刻板印象来做出推断，这可能会导致不准确或无效的推断结果。例如，在判断“会计吃了一个百吉饼”与“那个男人吃了一个百吉饼”或“那个女人吃了一个百吉饼”的关系时，理论上这两个句子之间的关系应该是中性的，因为“会计”这一身份与性别无关，不应该影响到句子的逻辑关系。然而，如果模型有偏见，它可能错误地认为这两个句子之间存在蕴含或矛盾关系，这表明模型在推理过程中受到了刻板印象的影响，没有正确处理信息，从而导致了错误的推断结果。</p></blockquote><ul><li>开发与部署生命周期中的偏见</li></ul><p> 训练数据可能只来自部分群体，而不能很好地利用在其它群体上；数据可能无法区分全部群体，而在需要对部分群体区别对待的基础上进行笼统概括</p><p> 模型中的偏差可能在于，训练和推理过程中放大了偏差；同时优化函数的不同选择如公平性或准确性的偏向也会影响模型；对训练样本的权衡，或者模型输出的排序也会影响模型偏差。</p><p> 基准数据集可能不能囊括所有使用大模型的群体，因此可以对已经囊括的群体进行优化</p><p> 大模型部署的环境可能和设定不同</p></li><li><p>大模型公平性的需要</p></li></ol><p>传统机器学习的公平性定义难以满足NLP任务的公平性需求，因此需要更多的定义来帮助实现NLP的公平性，此处见原文，我不会打公式。</p><p>然后罗列了一堆文章介绍到的各种公平性评估和公平性方法。</p><h2 id="偏差评估标准的分类"><a href="#偏差评估标准的分类" class="headerlink" title="偏差评估标准的分类"></a>偏差评估标准的分类</h2><p>在评估模型偏差过程中包含了几个层面：任务指向、偏差类型、数据结构、指标输入。</p><ol><li>基于替代的公平性评估</li></ol><p>通过比较文本输入是性别互换之后的句子，依据模型给出的结果进行差异比较</p><ol start="2"><li>基于用途的指标分类</li></ol><p>对大模型公平性分类的指标可以依据模型使用的东西如嵌入、概率、文本生成等进行分类。</p><ul><li><p>基于嵌入的指标<br>  词嵌入：很直观就是指代某一群体的特殊向量与中性词的余弦距离应当都一致而不能偏向一方<br>  句嵌入：相对于词嵌入，句子层级的嵌入更适合大模型，可以更有效地评估多维度的偏差</p><blockquote><p>关于基于嵌入的指标，文章中提到如果违反了社会对于某些群体的语言使用被违反，那么受保护属性的表示与其它词语的关联与下游任务表现的差异就完全独立了，就是有没有了受保护属性与其它词语的关联都没有关系。而且基于嵌入的评价指标可能高度依赖不同的设计选择，因此最好能避免使用，而是专注于特定下游任务的指标评估。</p></blockquote></li><li><p>基于概率的指标</p><ol><li>掩码token</li></ol><p>  就是给两个句子，句子主题是两个不同的社会群体，然后用预测词的概率分布差异来比较模型如何对待两个社会群体。</p><ol start="2"><li>伪对数似然</li></ol><p>  给定两个完整的句子，两个句子含有不同的社会群体，评估模型在给定每个单词的条件概率下，比较选择最终两个句子的可能。</p><blockquote><p>mask一个token，然后用其它没有被mask的token来预测这个token，用来近似条件概率</p></blockquote><ol start="3"><li>对数概率偏差分数LPBS</li></ol><p>  这个就是比较两个不同社会群体在用先验标准化的情况下，两个群体分别出现在一个含有中性词语句子中的对数概率差异</p><p>4. </p><p>  好无聊综述看的<br>  真没意思<br>  看看别的去好了</p><p>  缺陷与嵌入评估相似，似乎是和下游任务很少相关</p></li><li><p>基于文本生成的指标</p></li></ul><p>看图似乎是给定一个prompt然后让大模型生成，通过评判生成结果来评估公平性</p><h2 id="偏见缓解技术"><a href="#偏见缓解技术" class="headerlink" title="偏见缓解技术"></a>偏见缓解技术</h2><ul><li><p>预处理</p><ul><li><p>数据增强</p><blockquote><p>add new examples which is not biased to the training data</p></blockquote><p>看图也就是改变训练数据中的性别，就是反事实训练一样，让社会群体互相替代来训练模型，来达到平衡训练数据的目的。数据平衡的做法一般是让样本成对出现、或者让对立样本在训练集中平衡</p><blockquote><p>缺陷在哪里：受到不完整的单词对列表的限制，并且在交换术语时可能会引入语法错误。</p></blockquote></li><li><p>数据过滤与重新加权<br>过滤掉很有攻击性和偏见的数据，让那些现实世界受到偏见群体的样本权重增加，降低不受到偏见群体的样本权重</p></li><li><p>数据生成</p><blockquote><p>上面两种方法的缺陷在于需要识别每个偏差维度的示例，这些偏差可能会根据上下文、应用程序或所需行为而有所不同。<br>相似句子替换，也就是用更高质量的训练数据进行训练</p></blockquote></li><li><p>指令微调<br>在每个样本之前添加一个基调让模型以这个基调学习这个样本</p></li><li><p>基于投影的缓解<br>貌似是识别与保护属性有关的嵌入空间，然后改变上下文嵌入以清除偏见维度</p></li></ul></li><li><p>处理中</p><ul><li>结构修改<br>修改模型配置，利用适配器添加新的可训练参数</li><li>损失函数修改<br>用损失函数作为新指标，来平衡对立社会群体的属性偏见</li><li>选择参数更新<br>冻结大部分预训练参数而选择少部分参数进行更新，如果不冻结就有可能在微调过程中忘记预训练的内容，称为灾难性遗忘。</li><li>过滤模型参数<br>冻结全部参数，但以去偏为目标剪枝部分参数</li></ul></li><li><p>后处理</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 大模型论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>llama2cpp</title>
      <link href="/2024/03/05/llama2cpp/"/>
      <url>/2024/03/05/llama2cpp/</url>
      
        <content type="html"><![CDATA[<h1 id="本地部署llama2"><a href="#本地部署llama2" class="headerlink" title="本地部署llama2"></a>本地部署llama2</h1><p>根据B站视频攻略做的部署，<a href="https://www.bilibili.com/video/BV1m34y1M7dM?vd_source=4414e7cb68c1443baf8d60ed1c992278">无需GPU，本地部署Llama2-13B模型</a></p><ol><li>首先就是要在windows环境下安装wsl，这个是模拟linux环境的<br>查看有哪些linux系统可以进行安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --list --online</span><br></pre></td></tr></table></figure></li><li>复制你想安装的系统名称进行安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --install -d sys_name</span><br></pre></td></tr></table></figure>再根据要求创建用户名密码就行</li><li>更换存储区域，默认下载的wsl是下载在C盘，需要更换一下 ~~我的C盘不多了。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wsl -l -v # 显示已经安装了的系统</span><br><span class="line">wsl --export sys_name target_dir # sys_name=你的系统命， target_dir就是目标路径，我的是D：\Ubuntu-22.04.tar</span><br><span class="line">wsl --unregister sys_name # 将原来的删除</span><br><span class="line">wsl --import sys_name source_dir target_dir --version 2 # source_dir就是你希望它存储的位置</span><br></pre></td></tr></table></figure></li><li>启动！<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --distribution sys_name --user user_name # user_name是之前设置的用户名</span><br></pre></td></tr></table></figure></li><li>在wsl中下载<a href="https://docs.anaconda.com/free/miniconda/index.html">miniconda</a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><blockquote><p>得等个二十分钟左右，我就是在等的时候写的这个东西。。😭</p></blockquote></li></ol><p>下载完成后</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>然后阅读协议，一直回车然后yesyesyes就完成了安装</p><ol start="6"><li><p>刷新环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc # 会进入base环境</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 添加conda镜像</span><br><span class="line">pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # 添加pip镜像</span><br></pre></td></tr></table></figure></li><li><p>下载llama和llama.cpp，然后进入llama</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/facebookresearch/llama.git</span><br><span class="line">git clone https://github.com/ggerganov/llama.cpp.git</span><br><span class="line">cd llama</span><br><span class="line">ll</span><br></pre></td></tr></table></figure><p>进去之后可以看到有专门下载模型的脚本，然后要去官网获取下载链接</p></li></ol><h1 id="夭折！！"><a href="#夭折！！" class="headerlink" title="夭折！！"></a>夭折！！</h1><p>下载LLAMA模型的表单提交不了！提示“There was an error submitting your email address.”</p><p>算了， 用huggingface试试google gemma？</p>]]></content>
      
      
      
        <tags>
            
            <tag> 大模型实践 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode插件 hexo_helper</title>
      <link href="/2024/03/04/page/"/>
      <url>/2024/03/04/page/</url>
      
        <content type="html"><![CDATA[<h1 id="my-first-blog"><a href="#my-first-blog" class="headerlink" title="my first blog"></a>my first blog</h1><p>在学习过程中突然有了记笔记的想法，这样可以时时记录学习过程，免得导师问这周干了什么的时候只能擦汗，于是就想到了搭建个人博客，用日记记录日常学习的过程。<br>因为文档生成有一个固定的模板，方便博客框架对文档信息进行渲染显示，因此为了避免每次都需要复制粘贴这个模板，我就用自动化脚本的方式来完成这一过程。</p><span id="more"></span><h2 id="保存时运行脚本"><a href="#保存时运行脚本" class="headerlink" title="保存时运行脚本"></a>保存时运行脚本</h2><p>vscode中下载run on save插件，并在setting.json中文件进行设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&quot;emeraldwalk.runonsave&quot;: &#123;</span><br><span class="line">    &quot;commands&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;match&quot;: &quot;\\.md$&quot;,</span><br><span class="line">            &quot;cmd&quot;: &quot;python $&#123;workspaceFolder&#125;/your_script_path.py $&#123;file&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就能匹配所有md文件，在保存过程中调用python脚本，<br>python脚本是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取当前日期和时间</span></span><br><span class="line">current_datetime = datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">file_path = sys.argv[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_or_insert_updated_field</span>(<span class="params">content, current_datetime</span>):</span><br><span class="line">    <span class="comment"># 检测是否已存在updated字段，并准备相应的正则表达式</span></span><br><span class="line">    updated_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;updated: [\d-]+\s[\d:]+&#x27;</span>)</span><br><span class="line">    date_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;date: [\d-]+\s[\d:]+&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> updated_pattern.search(content):</span><br><span class="line">        <span class="comment"># 如果存在updated字段，则更新其值</span></span><br><span class="line">        updated_content = updated_pattern.sub(<span class="string">f&#x27;updated: <span class="subst">&#123;current_datetime&#125;</span>&#x27;</span>, content)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果不存在updated字段，找到date字段并在其下插入updated字段</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">replacement</span>(<span class="params"><span class="keyword">match</span></span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;<span class="keyword">match</span>.group(<span class="number">0</span>)&#125;</span>\nupdated: <span class="subst">&#123;current_datetime&#125;</span>&quot;</span></span><br><span class="line">        updated_content = date_pattern.sub(replacement, content)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> updated_content</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    content = file.read()</span><br><span class="line">    updated_content = update_or_insert_updated_field(content, current_datetime)</span><br><span class="line">    file.seek(<span class="number">0</span>)</span><br><span class="line">    file.write(updated_content)</span><br><span class="line">    file.truncate()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>它能自动获取md文档，并在文档顶部的模板中更新updated时间<br>使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page_name</span><br></pre></td></tr></table></figure><p>就能新建一个含有原始文档模板的文件</p><h2 id="vscode扩展插件"><a href="#vscode扩展插件" class="headerlink" title="vscode扩展插件"></a>vscode扩展插件</h2><p>乐坏了，上面的脚本不用了，我直接用gpt4，0基础从0开发了vscode插件。</p><blockquote><p>gpt4写起来很快，调试过程很漫长<br>而且没学过typescript，也没开发过vscode插件，测试代码非常非常困难<br>生成一个能初步完成要求的插件发布插件只有和gpt4交谈半个多小时，解决bug得要浪费一个下午</p></blockquote><p>步骤大概如下</p><ol><li>首先需要确保有node.js和vscode</li><li>运行下列代码来创建插件骨架<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install -g yo generator-code</span><br><span class="line">yo code</span><br></pre></td></tr></table></figure></li><li>然后就是代码内容了，在extension.ts中编写就行了<blockquote><p>具体见<a href="https://github.com/zuoqiumama/hexo_blog_helper">github</a></p></blockquote></li></ol><p>其中出现比较多的问题就是正则匹配的问题，不过出现什么问题把问题描述一遍给gpt4听就完事了。</p><ol start="4"><li>最后就是打包</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vsce package</span><br></pre></td></tr></table></figure><p>然后就能在vscode的插件市场的右上角以vsix的方式进行安装，就能使用了。</p><p>目前的功能只有在hexo项目下对新建的md文件插入顶部模板的作用，后续可能还会再加吧</p><p>累一天没多大收获的想法就是：可以学学prompt更好地来用gpt4</p><p>还要学习下typescript，感觉写插件什么的还挺有意思的，<br>下次想写一个自己的代码生成插件什么的</p><h1 id="hexo-helper-update"><a href="#hexo-helper-update" class="headerlink" title="hexo_helper update"></a>hexo_helper update</h1><p>现在插件可以在文件保存之后自动提交文档了，美妙的了<br>主要的逻辑就是我默认了如果文章有了标题之后就可以进行部署</p><p>代码也比较简单就是在保存的时候直接提交命令就行<br>代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">function deployHexoBlog() &#123;</span><br><span class="line">    <span class="keyword">return</span> new Promise((resolve, reject) =&gt; &#123;</span><br><span class="line">        //const options = &#123; cwd: <span class="string">&#x27;D:\\hexo_blog\\blog&#x27;</span> &#125;; // 替换为您的Hexo根目录</span><br><span class="line">        <span class="built_in">exec</span>(<span class="string">&#x27;cd D:\\hexo_blog\\blog &amp; hexo cl &amp; hexo g &amp; hexo d&#x27;</span>, (error, stdout, stderr) =&gt; &#123;</span><br><span class="line">            console.log(<span class="string">&#x27;stdout:&#x27;</span>, stdout);</span><br><span class="line">            console.log(<span class="string">&#x27;stderr:&#x27;</span>, stderr);</span><br><span class="line">            <span class="keyword">if</span> (error) &#123;</span><br><span class="line">                vscode.window.showErrorMessage(`🥵 Something wrong <span class="keyword">in</span> deploying blog: $&#123;error&#125;`, &#123; modal: true &#125;);</span><br><span class="line">                console.error(`<span class="built_in">exec</span> error: $&#123;error&#125;`);</span><br><span class="line">                reject(error);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            vscode.window.showInformationMessage(<span class="string">&#x27;🥳 Yes!Blog deployed successfully!&#x27;</span>);</span><br><span class="line">            resolve(stdout);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>全是GPT的功劳！<br>现在可以说我的插件该有名字了，也算是我的一个小项目<br>后期更新的话可能会引入配置文件了是，让模板和tags都能在配置中进行更改<br>再进一步可以引申到更多的文件类型和模板！🥰</p><h1 id="todo-list"><a href="#todo-list" class="headerlink" title="todo list"></a>todo list</h1><ul><li><input checked="" disabled="" type="checkbox"> 保存文件时弹出窗口选择文章tags</li><li><input checked="" disabled="" type="checkbox"> ~~完成一篇大模型公平性文献阅读 收集几篇大模型公平性论文</li><li><input checked="" disabled="" type="checkbox"> B站视频本地部署llama2 ~~下载不了模型纯纯小问题</li><li><input checked="" disabled="" type="checkbox"> 更新插件让它能在保存时自动提交</li><li><input disabled="" type="checkbox"> 搞个图床，找一些高清图像资源，把博客背景和文章封面什么的都换了</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 学习日常 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
